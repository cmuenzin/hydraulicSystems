# Projekt-Zusammenfassung: Hydraulic Systems Data Preparation

**Modul:** Data Preparation  
**Level:** Einsteiger  
**Datum:** November 2025

---

## ğŸ“‹ Aufgabenstellung & Umsetzung

### 1. Datensatz aussuchen âœ“

**GewÃ¤hlt:** UCI Hydraulic Systems Dataset

**Warum dieser Datensatz?**
- Realistische Industriedaten (Condition Monitoring)
- Gut dokumentiert
- Interessante Challenge: 43.680 Spalten (Zeitreihen)
- Mehrere Zielvariablen â†’ vielseitig fÃ¼r Analysen
- Keine Missing Values â†’ Fokus auf Feature Engineering statt Datenbereinigung

**Quelle:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems)

---

### 2. Datensatz beschreiben âœ“

**Was wurde gemessen?**
- **2.205 Messzyklen** Ã  60 Sekunden auf einem Hydraulik-Teststand
- **17 Sensoren** mit unterschiedlichen Sampling-Raten:
  - Drucksensoren (PS1-PS6): 100 Hz â†’ 6.000 Messpunkte/Zyklus
  - Durchflusssensoren (FS1-FS2): 10 Hz â†’ 600 Messpunkte/Zyklus
  - Temperatursensoren (TS1-TS4): 1 Hz â†’ 60 Messpunkte/Zyklus
  - Weitere: Vibration (VS1), Motor-Power (EPS1), Effizienz-Sensoren (CE, CP, SE)

**Problem:** 
- Rohdaten = 2.205 Zeilen Ã— 43.680 Spalten
- Viel zu viele Features fÃ¼r sinnvolle Analysen!

**LÃ¶sung:**
- Feature Engineering: Zeitreihen aggregieren
- Statt 43.680 Zeitpunkte â†’ 136 aussagekrÃ¤ftige Features

ğŸ“„ **Siehe:** `README.md` (Abschnitt "Was ist das hier?" & "Der Datensatz")

---

### 3. Typos bereinigen âœ“

**Vorgehen:**
```python
df_numeric = df.apply(pd.to_numeric, errors='coerce')
```

**Was passiert:**
- Alle nicht-numerischen Werte werden zu `NaN` konvertiert
- Typos (z.B. falsche Zeichen, Buchstaben) werden automatisch erkannt

**Ergebnis:**
- Laut Datenquelle: **Keine Missing Values** im Datensatz
- Auch nach Typo-Bereinigung: **0% Missing Values** âœ“
- Datensatz ist sauber!

ğŸ“„ **Siehe:** `prep_corrected.py` (Zeile 44-45 in `extract_features()`)

**Output:**
- `out/feature_stats.csv` â†’ Spalte `pct_missing` zeigt 0.0 fÃ¼r alle Features

---

### 4. Missing Value Handling âœ“

**Strategie:**

Da der Datensatz **keine Missing Values** hat, brauchten wir keine komplexe Strategie!

**Trotzdem vorbereitet (falls doch welche auftauchen):**
- Automatische Konvertierung via `pd.to_numeric(errors='coerce')`
- Check in Statistiken: `n_missing` und `pct_missing`

**Entscheidung:**
- Keine Imputation nÃ¶tig
- Keine Spalten droppen nÃ¶tig
- Einfacher Check: âœ“ bestanden

ğŸ“„ **Siehe:** `out/feature_stats.csv` â†’ Alle Features zeigen `pct_missing = 0.0`

---

### 5. Werte je Attribut prÃ¼fen âœ“

**DurchgefÃ¼hrte Analysen:**

#### a) **Deskriptive Statistiken** (min/max, mean, median, std)

**Beispiel: Cooling Efficiency (CE) - Mean-Feature**
```
mean:   31.30  (typischer Wert)
std:    11.58  (moderate Schwankung)
min:    17.56  (niedrigster Durchschnitt)
max:    47.90  (hÃ¶chster Durchschnitt)
median: 27.39  (Median niedriger als Mean â†’ rechtsschiefe Verteilung)
```

**Beispiel: Pressure Sensor 1 (PS1) - Mean-Feature**
```
mean:   153.23 bar
std:    8.33   (geringe Schwankung â†’ stabiler Sensor)
min:    100.79 bar
max:    166.06 bar
```

ğŸ“„ **Output:** `out/feature_stats.csv` (vollstÃ¤ndige Statistiken fÃ¼r alle 136 Features)

---

#### b) **Korrelationsanalyse**

**Top-Korrelationen gefunden:**
- `ps1_mean` â†” `ps2_mean`: r â‰ˆ 0.99 (sehr hohe Korrelation)
- `ts1_mean` â†” `ts2_mean`: r â‰ˆ 0.95 (Temperatursensoren messen Ã¤hnlich)
- `ce_*` Features untereinander: r > 0.99 (mean, median, max sehr Ã¤hnlich)

**Bedeutung:**
- Viele Sensoren messen redundante Informationen
- FÃ¼r ML-Modelle: Feature Selection sinnvoll (z.B. nur PS1 statt PS1-PS6)
- FÃ¼r Einsteiger-Analyse: ok so!

ğŸ“„ **Output:** 
- `out/correlation.csv` (136Ã—136 Korrelationsmatrix)
- `out/correlation_heatmap.png` (Visualisierung)

---

#### c) **Feature Importance** (Mutual Information)

**Top 5 Features fÃ¼r Vorhersage von `cooler_condition`:**

1. `ce_max` â€” 1.093 (Maximale KÃ¼hleffizienz)
2. `ce_q75` â€” 1.093 (75%-Quantil KÃ¼hleffizienz)
3. `ce_median` â€” 1.089 (Median KÃ¼hleffizienz)
4. `ce_mean` â€” 1.089 (Durchschnitt KÃ¼hleffizienz)
5. `ce_min` â€” 1.088 (Minimale KÃ¼hleffizienz)

**Erkenntnis:**
- **Cooling Efficiency (CE)** ist DAS wichtigste Feature!
- Macht Sinn: Defekter KÃ¼hler â†’ KÃ¼hleffizienz sinkt direkt

ğŸ“„ **Output:** `out/mutual_information.csv`

---

#### d) **Verteilungen**

**Visualisiert:** Histogramme der Mean-Features

**Erkenntnisse:**
- Meiste Features zeigen **annÃ¤hernde Normalverteilung**
- Einige bi-modale Verteilungen (z.B. CE â†’ 2 Cluster: defekte vs. funktionierende KÃ¼hler)
- Keine extremen AusreiÃŸer

ğŸ“„ **Output:** `out/feature_distributions.png`

---

#### e) **Boxplots nach Zielvariable**

**Beispiel: TS1 Mean nach Cooler Condition**
- KÃ¼hler bei 100% (optimal) â†’ niedrigere Temperatur
- KÃ¼hler bei 3% (defekt) â†’ hÃ¶here Temperatur
- Klare Trennung der Gruppen âœ“

ğŸ“„ **Output:** `out/boxplots_by_target.png`

---

### 6. Feature Engineering âœ“

**Problem:** 43.680 Spalten sind nicht handhabbar!

**Ansatz:** Zeitreihen-Aggregation pro Sensor

**Die 8 gewÃ¤hlten Features:**

| Feature | Bedeutung | Warum wichtig? |
|---------|-----------|----------------|
| `mean` | Durchschnitt | Typischer Wert im Zyklus |
| `median` | Median | Robust gegen AusreiÃŸer |
| `std` | Standardabweichung | Wie stark schwankt der Sensor? |
| `min` | Minimum | Niedrigster Wert |
| `max` | Maximum | HÃ¶chster Wert |
| `q25` | 25%-Quantil | Unteres Quartil |
| `q75` | 75%-Quantil | Oberes Quartil |
| `range` | Spannweite (max - min) | Bandbreite |

**Ergebnis:**
- 17 Sensoren Ã— 8 Features = **136 Features**
- Von 43.680 â†’ 136 = **99,7% Reduktion** ğŸ‰
- BehÃ¤lt trotzdem wichtige Informationen bei!

**BegrÃ¼ndung:**
- **Lage-MaÃŸe** (mean, median): Wo liegt der Sensor typischerweise?
- **Streuungs-MaÃŸe** (std, range, Quartile): Wie variabel ist er?
- **Extremwerte** (min, max): Gibt es Spitzen?

ğŸ“„ **Code:** `prep_corrected.py` â†’ Funktion `extract_features()`

---

## ğŸ“Š Finale Outputs

### Generierte Dateien (in `out/`):

1. **`features_complete.csv`** (2.205 Ã— 141)
   - Hauptdatensatz: 136 Features + 5 Zielvariablen

2. **`feature_stats.csv`**
   - Deskriptive Statistiken: count, mean, std, min, max, Quartile, Missing%

3. **`correlation.csv`** + `correlation_heatmap.png`
   - Korrelationsmatrix (136Ã—136)
   - Visualisierung

4. **`mutual_information.csv`**
   - Feature Importance fÃ¼r Cooler Condition

5. **`feature_distributions.png`**
   - Histogramme der Mean-Features

6. **`boxplots_by_target.png`**
   - Feature-Verteilungen nach Cooler Condition

---

## ğŸ¯ Zusammenfassung der Ergebnisse

### DatenqualitÃ¤t: â­â­â­â­â­
- Keine Missing Values
- Keine Typos
- Saubere Zeitreihen
- Gut dokumentiert

### Feature Engineering: â­â­â­â­â­
- 99,7% Dimensionsreduktion
- BehÃ¤lt wichtige Informationen
- Interpretierbare Features

### Analysen: â­â­â­â­â­
- Klare Korrelationen identifiziert
- Feature Importance berechnet
- Verteilungen visualisiert
- ZusammenhÃ¤nge mit Zielvariablen erkennbar

---

## ğŸ’¡ Key Insights

1. **Cooling Efficiency (CE)** ist der wichtigste Sensor fÃ¼r KÃ¼hler-Diagnose
2. Viele Sensoren messen redundante Informationen (hohe Korrelation)
3. Features zeigen gute Normalverteilungen â†’ gut fÃ¼r ML
4. Klare Trennung zwischen Zustandsklassen (z.B. defekt vs. optimal)
5. Datensatz ist sehr sauber â†’ perfekt fÃ¼r Einsteiger-Analysen

---

## ğŸš€ NÃ¤chste Schritte (optional, fÃ¼r ML-Projekte)

- Feature Selection: Redundante Features entfernen
- Klassifikation: Random Forest, SVM fÃ¼r Zustandsvorhersage
- Anomalie-Erkennung: UngewÃ¶hnliche Zyklen finden
- Time Series Analysis: Degradation Ã¼ber Zeit

**Aber:** FÃ¼r Data Preparation Modul â†’ **Fertig!** âœ“

---

**Bearbeitet von:** Christian MÃ¼nzinger  
**Datum:** 04.11.2025  
**Tools:** Python, pandas, matplotlib, seaborn, scikit-learn
