{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663848ea",
   "metadata": {},
   "source": [
    "# Hydraulic Systems - Data Exploration & Preparation\n",
    "\n",
    "## Kontext\n",
    "\n",
    "Die Daten enthalten **Zeitreihen-Messungen** von Sensoren:\n",
    "- **Zeilen** = Zyklen (2205 Messzyklen)\n",
    "- **Spalten** = Zeitpunkte innerhalb eines 60-Sekunden-Zyklus\n",
    "\n",
    "### Sensor-Sampling-Raten:\n",
    "- **100 Hz** (6000 Messpunkte): PS1-PS6, EPS1\n",
    "- **10 Hz** (600 Messpunkte): FS1, FS2  \n",
    "- **1 Hz** (60 Messpunkte): TS1-TS4, VS1, CE, CP, SE\n",
    "\n",
    "### Strategie:\n",
    "1. **Rohdaten laden** und Struktur verstehen\n",
    "2. **Feature Engineering**: Aggregationen pro Zyklus (mean, std, min, max, etc.)\n",
    "3. **Zielvariablen** aus profile.txt einbinden\n",
    "4. **Bereinigte Features** exportieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Plotting-Style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✓ Imports erfolgreich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d3e9c",
   "metadata": {},
   "source": [
    "## 1. Datenstruktur verstehen\n",
    "\n",
    "Schauen wir uns exemplarisch eine Datei an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: TS1 (Temperature Sensor 1, 1 Hz = 60 Messpunkte)\n",
    "ts1 = pd.read_csv('../data/TS1.txt', sep=r'\\s+', header=None, engine='python')\n",
    "\n",
    "print(f\"TS1 Shape: {ts1.shape}\")\n",
    "print(f\"  → {ts1.shape[0]} Zyklen\")\n",
    "print(f\"  → {ts1.shape[1]} Zeitpunkte pro Zyklus (1 Hz × 60 Sekunden)\\n\")\n",
    "\n",
    "print(\"Erste 5 Zyklen, erste 10 Zeitpunkte:\")\n",
    "ts1.iloc[:5, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2427a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: PS1 (Pressure Sensor 1, 100 Hz = 6000 Messpunkte)\n",
    "ps1 = pd.read_csv('../data/PS1.txt', sep=r'\\s+', header=None, engine='python')\n",
    "\n",
    "print(f\"PS1 Shape: {ps1.shape}\")\n",
    "print(f\"  → {ps1.shape[0]} Zyklen\")\n",
    "print(f\"  → {ps1.shape[1]} Zeitpunkte pro Zyklus (100 Hz × 60 Sekunden)\\n\")\n",
    "\n",
    "print(\"Erste 3 Zyklen, erste 10 Zeitpunkte:\")\n",
    "ps1.iloc[:3, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bcb23d",
   "metadata": {},
   "source": [
    "## 2. Visualisierung: Ein einzelner Zyklus\n",
    "\n",
    "Plotten wir einen kompletten Zyklus für TS1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zyklus #100 von TS1\n",
    "cycle_idx = 100\n",
    "cycle_data = ts1.iloc[cycle_idx, :].values\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(cycle_data, marker='.', linestyle='-', linewidth=0.8)\n",
    "plt.title(f'TS1 - Zyklus #{cycle_idx} (60 Sekunden @ 1 Hz)', fontsize=14)\n",
    "plt.xlabel('Zeitpunkt (0-59 Sekunden)')\n",
    "plt.ylabel('Temperatur (°C)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Min: {cycle_data.min():.2f} °C\")\n",
    "print(f\"Max: {cycle_data.max():.2f} °C\")\n",
    "print(f\"Mean: {cycle_data.mean():.2f} °C\")\n",
    "print(f\"Std: {cycle_data.std():.2f} °C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c9783",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering: Aggregationen\n",
    "\n",
    "Statt 43.680 Zeitpunkte zu nutzen, erstellen wir **aussagekräftige Features** pro Sensor/Zyklus:\n",
    "\n",
    "- `mean`: Durchschnitt\n",
    "- `std`: Standardabweichung (Variabilität)\n",
    "- `min`: Minimum\n",
    "- `max`: Maximum\n",
    "- `median`: Median\n",
    "- `q25`, `q75`: Quartile\n",
    "- `range`: max - min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edaa8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df, sensor_name):\n",
    "    \"\"\"\n",
    "    Extrahiert aggregierte Features aus Zeitreihen-DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame mit Zyklen × Zeitpunkten\n",
    "        sensor_name: Name des Sensors (z.B. 'ts1')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame mit aggregierten Features pro Zyklus\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Konvertiere zu numerisch (falls nötig)\n",
    "    df_numeric = df.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    features[f'{sensor_name}_mean'] = df_numeric.mean(axis=1)\n",
    "    features[f'{sensor_name}_std'] = df_numeric.std(axis=1)\n",
    "    features[f'{sensor_name}_min'] = df_numeric.min(axis=1)\n",
    "    features[f'{sensor_name}_max'] = df_numeric.max(axis=1)\n",
    "    features[f'{sensor_name}_median'] = df_numeric.median(axis=1)\n",
    "    features[f'{sensor_name}_q25'] = df_numeric.quantile(0.25, axis=1)\n",
    "    features[f'{sensor_name}_q75'] = df_numeric.quantile(0.75, axis=1)\n",
    "    features[f'{sensor_name}_range'] = features[f'{sensor_name}_max'] - features[f'{sensor_name}_min']\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test mit TS1\n",
    "ts1_features = extract_features(ts1, 'ts1')\n",
    "print(f\"TS1 Features Shape: {ts1_features.shape}\")\n",
    "print(f\"\\nSpalten: {list(ts1_features.columns)}\")\n",
    "print(\"\\nErste 5 Zeilen:\")\n",
    "ts1_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37765c5",
   "metadata": {},
   "source": [
    "## 4. Alle Sensoren verarbeiten\n",
    "\n",
    "Jetzt laden und aggregieren wir **alle** Sensor-Dateien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_aggregate_all(data_path='../data'):\n",
    "    \"\"\"\n",
    "    Lädt alle Sensor-Dateien und extrahiert aggregierte Features.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_path)\n",
    "    all_features = []\n",
    "    \n",
    "    sensor_files = sorted(data_dir.glob('*.txt'))\n",
    "    \n",
    "    for file_path in sensor_files:\n",
    "        sensor_name = file_path.stem.lower()\n",
    "        \n",
    "        print(f\"Verarbeite {sensor_name}...\", end=' ')\n",
    "        \n",
    "        # Lade Daten\n",
    "        df = pd.read_csv(file_path, sep=r'\\s+', header=None, engine='python')\n",
    "        \n",
    "        # Extrahiere Features\n",
    "        features = extract_features(df, sensor_name)\n",
    "        all_features.append(features)\n",
    "        \n",
    "        print(f\"✓ ({df.shape[0]} Zyklen × {df.shape[1]} Zeitpunkte → {features.shape[1]} Features)\")\n",
    "    \n",
    "    # Alle Features zusammenführen\n",
    "    combined = pd.concat(all_features, axis=1)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Führe aus\n",
    "features_df = load_and_aggregate_all()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Final Features Shape: {features_df.shape}\")\n",
    "print(f\"  → {features_df.shape[0]} Zyklen\")\n",
    "print(f\"  → {features_df.shape[1]} aggregierte Features\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersicht über Features\n",
    "print(\"Spaltenübersicht:\")\n",
    "print(features_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Zeilen\n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd759a",
   "metadata": {},
   "source": [
    "## 5. Zielvariablen laden (profile.txt)\n",
    "\n",
    "Laut Dokumentation enthält `profile.txt` die Ziel-Labels für jeden Zyklus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6049cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade profile.txt\n",
    "profile = pd.read_csv('../docs/profile.txt', sep='\\t', header=None)\n",
    "\n",
    "print(f\"Profile Shape: {profile.shape}\")\n",
    "print(f\"\\nErste 10 Zeilen:\")\n",
    "print(profile.head(10))\n",
    "\n",
    "print(f\"\\nUnique Werte pro Spalte:\")\n",
    "for i in range(profile.shape[1]):\n",
    "    print(f\"  Spalte {i}: {sorted(profile[i].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laut Dokumentation:\n",
    "# Spalte 0: Cooler condition (3, 20, 100)\n",
    "# Spalte 1: Valve condition\n",
    "# Spalte 2: Pump leakage\n",
    "# Spalte 3: Accumulator pressure\n",
    "# Spalte 4: Stable flag\n",
    "\n",
    "profile.columns = ['cooler_condition', 'valve_condition', 'pump_leakage', \n",
    "                   'accumulator_pressure', 'stable_flag']\n",
    "\n",
    "print(\"Profile mit Spaltennamen:\")\n",
    "profile.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522303d8",
   "metadata": {},
   "source": [
    "## 6. Features + Targets zusammenführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfe ob Längen übereinstimmen\n",
    "print(f\"Features: {len(features_df)} Zeilen\")\n",
    "print(f\"Profile:  {len(profile)} Zeilen\")\n",
    "\n",
    "# Füge zusammen\n",
    "df_complete = pd.concat([features_df.reset_index(drop=True), \n",
    "                         profile.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(f\"\\nKompletter Datensatz: {df_complete.shape}\")\n",
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e603d6",
   "metadata": {},
   "source": [
    "## 7. Basis-Statistiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiken nur für Features (nicht Targets)\n",
    "feature_cols = [col for col in df_complete.columns if col not in profile.columns]\n",
    "\n",
    "stats = df_complete[feature_cols].describe().T\n",
    "stats['missing'] = df_complete[feature_cols].isna().sum()\n",
    "stats['missing_pct'] = 100 * stats['missing'] / len(df_complete)\n",
    "\n",
    "print(\"Feature-Statistiken:\")\n",
    "stats[['count', 'missing', 'missing_pct', 'mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16607ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichere Statistiken\n",
    "stats.to_csv('../out/feature_stats.csv')\n",
    "print(\"✓ Statistiken gespeichert: out/feature_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c26cdf",
   "metadata": {},
   "source": [
    "## 8. Missing Values prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdef548",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_summary = pd.DataFrame({\n",
    "    'column': df_complete.columns,\n",
    "    'n_missing': df_complete.isna().sum().values,\n",
    "    'pct_missing': 100 * df_complete.isna().sum().values / len(df_complete)\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary['n_missing'] > 0].sort_values('n_missing', ascending=False)\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(\"Spalten mit Missing Values:\")\n",
    "    print(missing_summary)\n",
    "else:\n",
    "    print(\"✓ Keine Missing Values gefunden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046589f5",
   "metadata": {},
   "source": [
    "## 9. Korrelationsanalyse\n",
    "\n",
    "Jetzt mit vernünftiger Anzahl an Features (statt 43k):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e17983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelation nur für Features\n",
    "corr = df_complete[feature_cols].corr()\n",
    "\n",
    "print(f\"Korrelationsmatrix: {corr.shape}\")\n",
    "\n",
    "# Speichern\n",
    "corr.to_csv('../out/correlation.csv')\n",
    "print(\"✓ Korrelation gespeichert: out/correlation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a45fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap (alle Features)\n",
    "plt.figure(figsize=(20, 18))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, square=True, \n",
    "            linewidths=0.1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Korrelations-Heatmap (Alle Features)', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../out/correlation_heatmap_full.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Heatmap gespeichert: out/correlation_heatmap_full.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2533f",
   "metadata": {},
   "source": [
    "## 10. Top-Korrelationen finden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30683f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finde höchste Korrelationen (ohne Diagonale)\n",
    "corr_pairs = []\n",
    "\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        corr_pairs.append({\n",
    "            'feature1': corr.columns[i],\n",
    "            'feature2': corr.columns[j],\n",
    "            'correlation': corr.iloc[i, j]\n",
    "        })\n",
    "\n",
    "corr_pairs_df = pd.DataFrame(corr_pairs)\n",
    "corr_pairs_df = corr_pairs_df.sort_values('correlation', ascending=False, key=abs)\n",
    "\n",
    "print(\"Top 20 höchste Korrelationen:\")\n",
    "corr_pairs_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e053a",
   "metadata": {},
   "source": [
    "## 11. Visualisierungen: Feature-Verteilungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26117ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Mean-Features für verschiedene Sensoren\n",
    "mean_features = [col for col in feature_cols if '_mean' in col]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(mean_features[:16]):\n",
    "    axes[i].hist(df_complete[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(col, fontsize=10)\n",
    "    axes[i].set_xlabel('Wert')\n",
    "    axes[i].set_ylabel('Häufigkeit')\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../out/feature_distributions_mean.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Verteilungen gespeichert: out/feature_distributions_mean.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06e3db",
   "metadata": {},
   "source": [
    "## 12. Boxplots: Features nach Cooler Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: TS1 Mean nach Cooler Condition\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "features_to_plot = ['ts1_mean', 'ts2_mean', 'ps1_mean', 'ps2_mean']\n",
    "\n",
    "for i, feat in enumerate(features_to_plot):\n",
    "    if feat in df_complete.columns:\n",
    "        df_complete.boxplot(column=feat, by='cooler_condition', ax=axes[i])\n",
    "        axes[i].set_title(f'{feat} by Cooler Condition')\n",
    "        axes[i].set_xlabel('Cooler Condition')\n",
    "        axes[i].set_ylabel(feat)\n",
    "\n",
    "plt.suptitle('')  # Entferne automatischen Titel\n",
    "plt.tight_layout()\n",
    "plt.savefig('../out/boxplots_by_cooler.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Boxplots gespeichert: out/boxplots_by_cooler.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c195016",
   "metadata": {},
   "source": [
    "## 13. Export: Bereinigter Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30081fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportiere als Parquet (kompakt & schnell)\n",
    "df_complete.to_parquet('../out/features_complete.parquet', index=False)\n",
    "print(f\"✓ Gespeichert: out/features_complete.parquet ({df_complete.shape})\")\n",
    "\n",
    "# Auch als CSV (für einfache Ansicht)\n",
    "df_complete.to_csv('../out/features_complete.csv', index=False)\n",
    "print(f\"✓ Gespeichert: out/features_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a9baf",
   "metadata": {},
   "source": [
    "## 14. Zusammenfassung\n",
    "\n",
    "### Ergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe871487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ZUSAMMENFASSUNG\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDatenpunkte:\")\n",
    "print(f\"  • {df_complete.shape[0]:,} Zyklen\")\n",
    "print(f\"  • {len(feature_cols):,} aggregierte Features\")\n",
    "print(f\"  • {len(profile.columns)} Zielvariablen\")\n",
    "print(f\"\\nExportierte Dateien:\")\n",
    "print(f\"  • out/features_complete.parquet\")\n",
    "print(f\"  • out/features_complete.csv\")\n",
    "print(f\"  • out/feature_stats.csv\")\n",
    "print(f\"  • out/correlation.csv\")\n",
    "print(f\"  • out/correlation_heatmap_full.png\")\n",
    "print(f\"  • out/feature_distributions_mean.png\")\n",
    "print(f\"  • out/boxplots_by_cooler.png\")\n",
    "print(f\"\\nZielvariablen:\")\n",
    "for col in profile.columns:\n",
    "    unique_vals = df_complete[col].unique()\n",
    "    print(f\"  • {col}: {unique_vals}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
